{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\")\\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.memory\", \"1g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import s2sphere\n",
    "from pyspark.sql.types import StringType, FloatType\n",
    "\n",
    "def cell_id(level: int, lat: int, lng: int) -> str:\n",
    "    return s2sphere.CellId.from_lat_lng(s2sphere.LatLng.from_degrees(lat, lng)).parent(level).to_token()\n",
    "\n",
    "cell_id_udf = f.udf(cell_id, StringType())\n",
    "\n",
    "def sphere_distance(token_from: str, token_to: str) -> float:\n",
    "    r = 6373.0\n",
    "    cell_from = s2sphere.CellId.from_token(token_from)\n",
    "    cell_to = s2sphere.CellId.from_token(token_to)\n",
    "    return cell_from.to_lat_lng().get_distance(cell_to.to_lat_lng()).radians * r\n",
    "\n",
    "sphere_distance_udf = f.udf(sphere_distance, FloatType())\n",
    "\n",
    "train_df = spark.read.option('header', 'true').csv('../data/raw/train.csv')\\\n",
    ".select('pickup_datetime', 'pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude')\\\n",
    ".withColumnRenamed('pickup_latitude', 'pickup_lat')\\\n",
    ".withColumn('pickup_lat', f.col('pickup_lat').cast('double'))\\\n",
    ".withColumnRenamed('pickup_longitude', 'pickup_lon')\\\n",
    ".withColumn('pickup_lon', f.col('pickup_lon').cast('double'))\\\n",
    ".withColumnRenamed('dropoff_latitude', 'dropoff_lat')\\\n",
    ".withColumn('dropoff_lat', f.col('dropoff_lat').cast('double'))\\\n",
    ".withColumnRenamed('dropoff_longitude', 'dropoff_lon')\\\n",
    ".withColumn('dropoff_lon', f.col('dropoff_lon').cast('double'))\\\n",
    ".withColumn('pickup_cell', cell_id_udf(f.lit(18), f.col('pickup_lat'), f.col('pickup_lon')))\\\n",
    ".withColumn('dropoff_cell', cell_id_udf(f.lit(18), f.col('dropoff_lat'), f.col('dropoff_lon')))\n",
    "\n",
    "test_df = spark.read.option('header', 'true').csv('../data/raw/test.csv')\\\n",
    ".select('pickup_datetime', 'pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude')\\\n",
    ".withColumnRenamed('pickup_latitude', 'pickup_lat')\\\n",
    ".withColumn('pickup_lat', f.col('pickup_lat').cast('double'))\\\n",
    ".withColumnRenamed('pickup_longitude', 'pickup_lon')\\\n",
    ".withColumn('pickup_lon', f.col('pickup_lon').cast('double'))\\\n",
    ".withColumnRenamed('dropoff_latitude', 'dropoff_lat')\\\n",
    ".withColumn('dropoff_lat', f.col('dropoff_lat').cast('double'))\\\n",
    ".withColumnRenamed('dropoff_longitude', 'dropoff_lon')\\\n",
    ".withColumn('dropoff_lon', f.col('dropoff_lon').cast('double'))\\\n",
    ".withColumn('pickup_cell', cell_id_udf(f.lit(18), f.col('pickup_lat'), f.col('pickup_lon')))\\\n",
    ".withColumn('dropoff_cell', cell_id_udf(f.lit(18), f.col('dropoff_lat'), f.col('dropoff_lon')))\n",
    "\n",
    "df = train_df.union(test_df)\\\n",
    ".select('pickup_cell', 'dropoff_cell')\\\n",
    ".dropDuplicates()\\\n",
    ".withColumn('distance', sphere_distance_udf(f.col('pickup_cell'), f.col('dropoff_cell')))\n",
    "\n",
    "#df.write.parquet('../data/processed/distance_matrix', mode='overwrite')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+---------+\n",
      "|pickup_cell|dropoff_cell| distance|\n",
      "+-----------+------------+---------+\n",
      "| 89c259ae67|  89c258ec75|3.0498326|\n",
      "| 89c259bd67|  89c258596f| 3.545008|\n",
      "| 89c2599283|  89c2585891|4.7375374|\n",
      "+-----------+------------+---------+\n",
      "only showing top 3 rows\n",
      "\n",
      "root\n",
      " |-- pickup_cell: string (nullable = true)\n",
      " |-- dropoff_cell: string (nullable = true)\n",
      " |-- distance: float (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2000986"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.show(3)\n",
    "df.printSchema()\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pipeline-oriented-analytics]",
   "language": "python",
   "name": "conda-env-pipeline-oriented-analytics-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
