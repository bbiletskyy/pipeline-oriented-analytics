{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\")\\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.memory\", \"1g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------------+--------+\n",
      "|pickup_cell_14|dropoff_cell_14|distance|\n",
      "+--------------+---------------+--------+\n",
      "|      89c25983|       89c25e61|    8.44|\n",
      "|      89c25859|       89c25857|    0.55|\n",
      "|      89c25ff3|       89c258ff|   10.01|\n",
      "|      89c26655|       89c2599d|   18.74|\n",
      "+--------------+---------------+--------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pipeline_oriented_analytics.dataframe import CsvDataFrame, ParquetDataFrame\n",
    "ParquetDataFrame('../data/processed/distance_matrix', spark).show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1458644 rows of train inputs\n"
     ]
    }
   ],
   "source": [
    "from pipeline_oriented_analytics.pipe import Pipe, IF\n",
    "from pipeline_oriented_analytics.transformer import *\n",
    "from typing import List, Dict\n",
    "from pipeline_oriented_analytics.dataframe import CsvDataFrame, ParquetDataFrame\n",
    "from pipeline_oriented_analytics import Phase\n",
    "\n",
    "phase = Phase.train\n",
    "#phase = Phase.predict\n",
    "\n",
    "variables = ['id', 'pickup_datetime', 'pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude']\n",
    "lables = ['trip_duration']\n",
    "column_names = {'pickup_longitude': 'pickup_lon', 'pickup_latitude': 'pickup_lat', 'dropoff_longitude': 'dropoff_lon', 'dropoff_latitude': 'dropoff_lat', 'trip_duration': 'duration_sec'}\n",
    "variable_types = {'id': 'string', 'pickup_datetime': 'timestamp', 'pickup_lon': 'double', 'pickup_lat': 'double', 'dropoff_lon': 'double', 'dropoff_lat': 'double'}\n",
    "label_types = {'duration': 'int'}\n",
    "\n",
    "if phase.is_predict():\n",
    "    columns = variables\n",
    "    column_types = variable_types\n",
    "    data_path = '../data/raw/test.csv'\n",
    "else: \n",
    "    columns = variables + lables\n",
    "    column_types = {**variable_types, **label_types}\n",
    "    data_path = '../data/raw/train.csv'\n",
    "\n",
    "df = Pipe([\n",
    "    SelectColumns(columns),\n",
    "    RenameColumns(column_names),\n",
    "    NormalizeColumnTypes(column_types),\n",
    "    CellToken(8, 'pickup_lat', 'pickup_lon', 'pickup_cell_8'),\n",
    "    CellToken(8, 'dropoff_lat', 'dropoff_lon', 'dropoff_cell_8'),\n",
    "    CellToken(14, 'pickup_lat', 'pickup_lon', 'pickup_cell_14'),\n",
    "    CellToken(14, 'dropoff_lat', 'dropoff_lon', 'dropoff_cell_14'),\n",
    "    Join(['pickup_cell_14', 'dropoff_cell_14'], Join.Method.left, ParquetDataFrame('../data/processed/distance_matrix', spark)),\n",
    "    DropColumns(inputCols=['pickup_lat', 'pickup_lon', 'dropoff_lon', 'dropoff_lat', 'pickup_cell_14', 'dropoff_cell_14']),\n",
    "    #SaveToParquet(f'../data/processed/{phase.name}/inputs'),\n",
    "]).transform(CsvDataFrame(data_path, spark))\n",
    "\n",
    "print(f'Saved {df.count()} rows of {phase.name} inputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('dropoff_cell_8').groupby('dropoff_cell_8').count().sort(f.desc('count')).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------------+--------+\n",
      "|pickup_cell_14|dropoff_cell_14|distance|\n",
      "+--------------+---------------+--------+\n",
      "|      89c25983|       89c25e61|    8.44|\n",
      "|      89c25859|       89c25857|    0.55|\n",
      "|      89c25ff3|       89c258ff|   10.01|\n",
      "|      89c26655|       89c2599d|   18.74|\n",
      "|      89c2599b|       89c25901|    2.75|\n",
      "|      89c25859|       89c259c7|    3.09|\n",
      "|      89c259a7|       89c25859|    2.75|\n",
      "|      89c259ad|       89c25885|    3.86|\n",
      "|      89c25853|       89c25a1d|    4.99|\n",
      "|      89c25857|       89c25ed9|    5.85|\n",
      "|      89c2f671|       89c2589d|    3.53|\n",
      "|      89c2590f|       89c25979|    2.16|\n",
      "|      89c25851|       89c2f67d|    7.99|\n",
      "|      89c2665f|       89c25a29|   19.96|\n",
      "|      89c258ef|       89c2598d|     5.3|\n",
      "|      89c259ab|       89c259b9|     1.7|\n",
      "|      89c25a11|       89c259af|    4.99|\n",
      "|      89c258ff|       89c2585b|    1.62|\n",
      "|      89c25853|       89c2590b|    2.58|\n",
      "|      89c2599f|       89c2584d|     3.1|\n",
      "+--------------+---------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ParquetDataFrame('../data/processed/distance_matrix', spark).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('dropoff_cell_8').groupby('dropoff_cell_8').count().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('dropoff_cell_8').dropDuplicates().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------+\n",
      "|dropoff_cell_8|  count|\n",
      "+--------------+-------+\n",
      "|         89c25|1341333|\n",
      "|         89c2f|  95207|\n",
      "|         89c27|  19989|\n",
      "|         89c29|   1742|\n",
      "|         89c3b|    111|\n",
      "|         89e83|     73|\n",
      "|         89c2b|     42|\n",
      "|         89c3d|     23|\n",
      "|         89c31|     17|\n",
      "|         89e81|     14|\n",
      "|         89c23|     14|\n",
      "|         89c2d|      9|\n",
      "|         89e9d|      7|\n",
      "|         89c39|      6|\n",
      "|         89e7d|      5|\n",
      "|         89c3f|      5|\n",
      "|         89b7b|      4|\n",
      "|         89b7d|      2|\n",
      "|         89dd3|      2|\n",
      "|         89e85|      2|\n",
      "+--------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('dropoff_cell_8').groupby('dropoff_cell_8').count().sort(f.desc('count')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pipeline-oriented-analytics]",
   "language": "python",
   "name": "conda-env-pipeline-oriented-analytics-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
