{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\")\\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.memory\", \"1g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+------------+-------------+--------------+--------+\n",
      "|       id|    pickup_datetime|duration_sec|pickup_cell_8|dropoff_cell_8|distance|\n",
      "+---------+-------------------+------------+-------------+--------------+--------+\n",
      "|id1090265|2016-02-09 21:30:46|         234|        89c25|         89c25|    1.12|\n",
      "|id0429543|2016-05-26 18:12:10|         600|        89c25|         89c25|    1.77|\n",
      "|id0588876|2016-03-12 23:59:16|        1501|        89c25|         89c25|    8.49|\n",
      "|id1046728|2016-04-16 03:18:55|        1124|        89c25|         89c25|    5.66|\n",
      "|id2457924|2016-03-02 22:53:19|         223|        89c25|         89c25|    1.12|\n",
      "|id1997531|2016-04-03 18:43:29|        2358|        89c25|         89c25|    8.01|\n",
      "|id1160205|2016-01-16 01:33:09|         758|        89c25|         89c25|    2.16|\n",
      "|id3824700|2016-04-13 22:35:04|         459|        89c25|         89c25|    3.26|\n",
      "|id2614722|2016-05-11 18:53:28|         287|        89c25|         89c25|     0.5|\n",
      "|id3385448|2016-06-02 22:10:08|         814|        89c25|         89c25|    6.54|\n",
      "|id2745967|2016-04-29 21:05:34|         216|        89c25|         89c25|    1.01|\n",
      "|id1934153|2016-02-06 07:21:54|         620|        89c25|         89c25|    2.89|\n",
      "|id1121722|2016-06-25 17:02:16|         989|        89c25|         89c25|    0.55|\n",
      "|id0033330|2016-05-09 22:56:01|         415|        89c25|         89c25|    1.65|\n",
      "|id3498200|2016-03-29 09:40:56|        1261|        89c25|         89c25|    2.58|\n",
      "|id0837192|2016-02-15 13:06:43|         353|        89c25|         89c25|    1.62|\n",
      "|id3464756|2016-04-22 18:13:22|         297|        89c25|         89c25|    1.06|\n",
      "|id0466397|2016-01-02 17:08:45|         587|        89c25|         89c25|    0.67|\n",
      "|id2359163|2016-05-21 20:00:48|        1070|        89c25|         89c25|    3.09|\n",
      "|id1602560|2016-03-27 12:15:55|        1047|        89c25|         89c25|    6.53|\n",
      "+---------+-------------------+------------+-------------+--------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ParquetDataFrame(f'../data/processed/train/inputs', spark).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 625134 rows predict features\n",
      "+--------------+-------------+---------+--------+-----+------------+-----------+----+--------------------+---------------------+\n",
      "|dropoff_cell_6|pickup_cell_6|       id|distance|month|day_of_month|day_of_week|hour|requests_pickup_cell|requests_dropoff_cell|\n",
      "+--------------+-------------+---------+--------+-----+------------+-----------+----+--------------------+---------------------+\n",
      "|          89c3|         89c3|id0557539|     1.7|    1|           2|          7|  22|                  39|                   39|\n",
      "|          89c3|         89c3|id0482177|    2.48|    1|           2|          7|  22|                  39|                   39|\n",
      "+--------------+-------------+---------+--------+-----+------------+-----------+----+--------------------+---------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pipeline_oriented_analytics.pipe import Pipe, IF\n",
    "from pipeline_oriented_analytics.transformer import *\n",
    "from pipeline_oriented_analytics.transformer.feature import *\n",
    "from typing import List, Dict\n",
    "from pipeline_oriented_analytics.dataframe import CsvDataFrame, ParquetDataFrame\n",
    "from pipeline_oriented_analytics import Phase\n",
    "\n",
    "#phase = Phase.train\n",
    "phase = Phase.predict\n",
    "\n",
    "features_df = Pipe([\n",
    "    Time('pickup_datetime', [Time.Feature.month, Time.Feature.day_of_month, Time.Feature.day_of_week, Time.Feature.hour]),\n",
    "    AddMinutes(-15, 'pickup_datetime', '15_min_before'),\n",
    "    RequestCount(15, 'pickup_cell_8', '15_min_before', 'requests_pickup_cell'),\n",
    "    RequestCount(15, 'dropoff_cell_8', '15_min_before', 'requests_dropoff_cell'),\n",
    "    IF(phase.is_train(), then=[\n",
    "        Duration(Duration.Unit.minute, 'duration_sec', 'duration_min'),\n",
    "        DropColumns(inputCols=['duration_min'], ),\n",
    "        DropOutliers('')\n",
    "    ]),\n",
    "    DropColumns(inputCols=['pickup_datetime', '15_min_before']),\n",
    "   SaveToParquet(f'../data/processed/{phase.name}/features')\n",
    "]).transform(ParquetDataFrame(f'../data/processed/{phase.name}/inputs', spark))\n",
    "\n",
    "print(f'Saved {features_df.count()} rows {phase.name} features')\n",
    "features_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pipeline-oriented-analytics]",
   "language": "python",
   "name": "conda-env-pipeline-oriented-analytics-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
